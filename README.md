# Toxic-Twitter-Comments
MLH Fellowship Orientation Hackathon Open Source Spring '21
### Project Objective
This project helps to classify comments based on the following toxicity levels.
- toxic
- severe toxic
- obscene
- threat
- insult
- identity hate
### Dependencies
- bentoml==0.11.0
- tensorflow==1.14.0
- keras==2.3.1
- pandas==1.1.5
- numpy==1.19.5
### Quick Start Guide
* Clone the project repository
* Run the model.py file but be sure to have the required dependencies installed before running the model
